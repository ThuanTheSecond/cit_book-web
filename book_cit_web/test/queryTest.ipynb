{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from django_for_jupyter import init_django\n",
    "init_django()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    book_id                                            content\n",
      "0      3001  CDMA capacity and quality optimization code di...\n",
      "1      3002  Image databases : Search and retrieval of digi...\n",
      "2      3003  Practical handbook on image processing for sci...\n",
      "3      3004  Analytics, data science, & artificial intellig...\n",
      "4      3005  Composing cyberspace : Identity, community, an...\n",
      "..      ...                                                ...\n",
      "74     3075  Digital image processing Image processing Digi...\n",
      "75     3076  Digital image processing using MATLAB Image pr...\n",
      "76     3078  Database systems the complete book Database de...\n",
      "77     3080  Data structures and abstractions with Java Jav...\n",
      "78     3081  MySQL/PHP database applications database appli...\n",
      "\n",
      "[79 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# tạo dataframe content chứa dữ liệu cho gợi ý dựa trên thể loại\n",
    "from home.models import Book_Topic, Book\n",
    "from home.models import ContentBook\n",
    "import pandas as pd\n",
    "books = Book.objects.all().order_by('book_id')\n",
    "bookTopic = Book_Topic.objects.prefetch_related('topic_id').order_by('book_id')\n",
    "check = True\n",
    "dics = []\n",
    "for book in books:\n",
    "    content = book.book_title\n",
    "    topics = bookTopic.filter(book_id = book.book_id)\n",
    "    for topic in topics:\n",
    "        content+=' '+topic.topic_id.topic_name\n",
    "    dic = {'book_id': book.book_id,\n",
    "            'content': content\n",
    "           }\n",
    "    dics.append(dic) \n",
    "book_df = pd.DataFrame(dics)\n",
    "print(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    book_id                                            content\n",
      "0      3001  CDMA capacity and quality optimization code di...\n",
      "1      3002  Image databases : Search and retrieval of digi...\n",
      "2      3003  Practical handbook on image processing for sci...\n",
      "3      3004  Analytics, data science, & artificial intellig...\n",
      "4      3005  Composing cyberspace : Identity, community, an...\n",
      "..      ...                                                ...\n",
      "74     3075  Digital image processing Image processing Digi...\n",
      "75     3076  Digital image processing using MATLAB Image pr...\n",
      "76     3078  Database systems the complete book Database de...\n",
      "77     3080  Data structures and abstractions with Java App...\n",
      "78     3081  MySQL/PHP database applications Database desig...\n",
      "\n",
      "[79 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from home.models import ContentBook\n",
    "import pandas as pd\n",
    "bookContent = ContentBook.objects.all().order_by('book_id')\n",
    "dics = []\n",
    "for book in bookContent:\n",
    "    dic = {\n",
    "        'book_id': book.book_id,\n",
    "        'content': book.content\n",
    "    }\n",
    "    dics.append(dic)\n",
    "book_df = pd.DataFrame(dics)\n",
    "print(book_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enlish_stop_words = text.ENGLISH_STOP_WORDS\n",
    "vietnamese_stop_words = [\"và\", \"là\", \"của\", \"những\", \"với\", \"từ\", \"một\", \"được\", \"khi\", \"đã\", \"cho\", \"vì\", \"ở\", \"này\", \"giáo\", \"trình\", \"lập\", \"trình\"]\n",
    "combine_stop_words = list(enlish_stop_words) + vietnamese_stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "book_tfidf = TfidfVectorizer(stop_words=combine_stop_words)\n",
    "book_df['content'] = book_df['content'].fillna('')\n",
    "book_content_matrix = book_tfidf.fit_transform(book_df['content'])\n",
    "book_content_matrix.shape\n",
    "\n",
    "cosine_similarity = linear_kernel(book_content_matrix, book_content_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Lưu TF-IDF Vectorizer\n",
    "with open('./home/recommend/book_tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(book_tfidf, f)\n",
    "\n",
    "with open('./home/recommend/book_cosine_similarity.pkl', 'wb') as f:\n",
    "    pickle.dump(cosine_similarity, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m bookContents \u001b[38;5;241m=\u001b[39m ContentBook\u001b[38;5;241m.\u001b[39mobjects\u001b[38;5;241m.\u001b[39mall()\u001b[38;5;241m.\u001b[39morder_by(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbook_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m book_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(bookContents)   \n\u001b[1;32m----> 7\u001b[0m book_content_matrix \u001b[38;5;241m=\u001b[39m book_tfidf\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mbook_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)  \n",
      "File \u001b[1;32mc:\\Users\\thait\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\thait\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'content'"
     ]
    }
   ],
   "source": [
    "from home.models import ContentBook\n",
    "import pickle\n",
    "with open('./home/recommend/book_tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    book_tfidf = pickle.load(f)\n",
    "bookContents = ContentBook.objects.all().order_by('book_id')\n",
    "book_df = pd.DataFrame(bookContents)   \n",
    "book_content_matrix = book_tfidf.fit_transform(book_df['content'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cosine_similarity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Thao tac tinh toan va dua ra goi y\u001b[39;00m\n\u001b[0;32m      2\u001b[0m choice \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m67\u001b[39m\n\u001b[1;32m----> 3\u001b[0m similarity_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(\u001b[43mcosine_similarity\u001b[49m[choice\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m      4\u001b[0m similarity_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(similarity_scores, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m similarity_scores \u001b[38;5;241m=\u001b[39m similarity_scores[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m6\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cosine_similarity' is not defined"
     ]
    }
   ],
   "source": [
    "# Thao tac tinh toan va dua ra goi y\n",
    "choice = 67\n",
    "similarity_scores = list(enumerate(cosine_similarity[choice-1]))\n",
    "similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "similarity_scores = similarity_scores[1:6]\n",
    "\n",
    "# Get the similar books index\n",
    "books_index = [i[0] for i in similarity_scores]\n",
    "books = Book.objects.all().order_by('book_id')\n",
    "# printing the top 5 most similar books using integer-location based indexing (iloc)\n",
    "print(f'The choice is: {books[choice-1].book_id} {books[choice-1].book_title}')\n",
    "for i in books_index:\n",
    "    print(f'{books[i].book_id} - {books[i].book_title} ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giả sử bạn có dữ liệu về sách mới\n",
    "new_books_df['content'] = new_books_df['content'].fillna('')\n",
    "\n",
    "# Vector hóa nội dung sách mới\n",
    "new_book_content_matrix = book_tfidf.transform(new_books_df['content'])\n",
    "\n",
    "# Cập nhật ma trận cosine similarity\n",
    "new_cosine_similarity = linear_kernel(new_book_content_matrix, book_content_matrix)\n",
    "\n",
    "# Gộp ma trận cũ và mới lại để cập nhật toàn bộ hệ thống\n",
    "cosine_similarity = linear_kernel(book_content_matrix, book_content_matrix)\n",
    "\n",
    "# Lưu lại các dữ liệu đã cập nhật\n",
    "with open('book_tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(book_tfidf, f)\n",
    "\n",
    "with open('book_cosine_similarity.pkl', 'wb') as f:\n",
    "    pickle.dump(cosine_similarity, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from django_for_jupyter import init_django\n",
    "init_django()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database systems the complete book Database design (Thiết kế database) Database management (Quản trị database)\n",
      "Database systems the complete book Database design (Thiết kế database) Database management (Quản trị database)\n"
     ]
    }
   ],
   "source": [
    "from home.models import ContentBook, Book, Book_Topic\n",
    "import pandas as pd\n",
    "latest_book = Book.objects.latest('book_id')\n",
    "content = latest_book.book_title\n",
    "topics = Book_Topic.objects.filter(book_id=latest_book.book_id).select_related('topic_id')\n",
    "for topic in topics:\n",
    "    content+=' '+ topic.topic_id.topic_name\n",
    "print(content)\n",
    "# newContent = ContentBook(book = latest_book, content = content)\n",
    "# newContent.save()\n",
    "newContentDic ={\n",
    "    'book_id': latest_book.book_id,\n",
    "    'content': content\n",
    "}\n",
    "newContent_df = pd.DataFrame(newContentDic, index=[0])\n",
    "print(newContent_df['content'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<enumerate object at 0x000001F519857790>\n"
     ]
    }
   ],
   "source": [
    "from home.models import ContentBook\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import pickle\n",
    "import pandas as pd\n",
    "    \n",
    "    \n",
    "with open('./home/recommend/book_tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    book_tfidf = pickle.load(f)\n",
    "\n",
    "bookContents = ContentBook.objects.all().order_by('book_id').values('book_id', 'content')\n",
    "book_df = pd.DataFrame(bookContents)\n",
    "book_df['content'] = book_df['content'].fillna('')\n",
    "book_df['content'] = book_df['content'].astype(str)\n",
    "\n",
    "    \n",
    "book_content_matrix = book_tfidf.fit_transform(book_df['content']) \n",
    "    \n",
    "cosine_similarity = linear_kernel(book_content_matrix, book_content_matrix)\n",
    "print(enumerate(cosine_similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, 3009, 3010, 3011, 3012, 3013, 3014, 3015, 3016, 3017, 3018, 3019, 3020, 3021, 3022, 3023, 3024, 3025, 3026, 3027, 3028, 3029, 3030, 3031, 3032, 3033, 3034, 3035, 3036, 3037, 3038, 3039, 3040, 3041, 3042, 3043, 3044, 3045, 3046, 3047, 3048, 3049, 3050, 3051, 3052, 3053, 3054, 3055, 3056, 3057, 3058, 3059, 3060, 3061, 3062, 3063, 3064, 3065, 3066, 3067, 3068, 3069, 3070, 3071, 3072, 3073, 3074, 3075, 3076, 3078, 3079, 3080, 3081]\n",
      "\n",
      "[80 rows x 0 columns]\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "from home.models import ContentBook\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "bookContents = ContentBook.objects.all().order_by('book_id').values('book_id')\n",
    "book_df = pd.DataFrame(bookContents)\n",
    "book_id = 3032\n",
    "book_df.set_index('book_id', inplace=True)\n",
    "print(book_df)\n",
    "book_index = book_df.index.get_loc(book_id)\n",
    "print(book_index)\n",
    "with open('./home/recommend/book_cosine_similarity.pkl', 'rb') as f:\n",
    "    cosine_similarity = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from home.models import ContentBook\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "books = ContentBook.objects.all().order_by('book_id').values('book_id', 'content')\n",
    "book_df = pd.DataFrame(books)\n",
    "book_df['content'] = book_df['content'].fillna('')\n",
    "\n",
    "enlish_stop_words = text.ENGLISH_STOP_WORDS\n",
    "vietnamese_stop_words = [\"và\", \"là\", \"của\", \"những\", \"với\", \"từ\", \"một\", \"được\", \"khi\", \"đã\", \"cho\", \"vì\", \"ở\", \"này\", \"giáo\", \"trình\", \"lập\", \"trình\"]\n",
    "combine_stop_words = list(enlish_stop_words) + vietnamese_stop_words\n",
    "book_tfidf = TfidfVectorizer(stop_words=combine_stop_words)\n",
    "book_content_matrix = book_tfidf.fit_transform(book_df['content']) \n",
    "\n",
    "cosine_similarities = linear_kernel(book_content_matrix, book_content_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The choice is: 3032 Cisco The complete reference\n",
      "3045 - Giáo trình mạng máy tính \n",
      "3013 - Data communications, computer networks and open systems \n",
      "3062 - Giáo trình quản trị hệ thống mạng \n",
      "3064 - Giáo trình các hệ thống phân tán \n",
      "3031 - The complete reference Java 2 \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Thao tac tinh toan va dua ra goi y\n",
    "\n",
    "\n",
    "choice = book_index\n",
    "similarity_scores = list(enumerate(cosine_similarity[choice]))\n",
    "similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "similarity_scores = similarity_scores[2:7]\n",
    "\n",
    "# Get the similar books index\n",
    "books_index = [i[0] for i in similarity_scores]\n",
    "from home.models import Book\n",
    "books = Book.objects.all().order_by('book_id')\n",
    "# printing the top 5 most similar books using integer-location based indexing (iloc)\n",
    "print(f'The choice is: {books[choice].book_id} {books[choice].book_title}')\n",
    "for i in books_index:\n",
    "    print(f'{books[i].book_id} - {books[i].book_title} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data structure (cấu trúc dữ liệu)\n",
      "Perl database programming Data structure (cấu trúc dữ liệu)\n",
      "Database structure\n",
      "Perl database programming Data structure (cấu trúc dữ liệu) Database structure\n",
      "   book_id                                            content\n",
      "0     3079  Perl database programming Data structure (cấu ...\n"
     ]
    }
   ],
   "source": [
    "# ham update content book khi update bôok\n",
    "# lay ra title, topics của cuốn sách mới nhất được cập nhật thông qua created_at\n",
    "# chạy lại vòng lặp topic và cập nhật content dựa vào book_id\n",
    "from home.models import ContentBook, Book, Book_Topic\n",
    "import pandas as pd\n",
    "lasted_update = Book.objects.latest('created_at')\n",
    "\n",
    "content = lasted_update.book_title\n",
    "content = str(content)\n",
    "topics = Book_Topic.objects.filter(book_id_id = lasted_update.book_id).select_related('topic_id')\n",
    "for topic in topics:\n",
    "    print(str(topic.topic_id.topic_name))\n",
    "    content+=' '+ str(topic.topic_id.topic_name)\n",
    "    print(content)\n",
    "content_update = ContentBook.objects.get(book_id = lasted_update.book_id)\n",
    "content_update.content = content\n",
    "content_update.save()\n",
    "\n",
    "updateContentDic = {\n",
    "    'book_id': lasted_update.book_id,\n",
    "    'content': content\n",
    "}\n",
    "updateContent_df = pd.DataFrame(updateContentDic, index=[0])\n",
    "print(updateContent_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'django.db.models.query.QuerySet'>\n"
     ]
    }
   ],
   "source": [
    "from home.models import Book\n",
    "book_id = 3076\n",
    "bookList = Book.objects.all().order_by('book_id')\n",
    "detail = bookList.filter(book_id = book_id).first()\n",
    "print(type(bookList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46-Giáo trình kiểm thử phần mềm,Trần, Cao Đệ,Cần Thơ: Nxb. Đại học Cần Thơ, 2012,004.63 / H513,179794,True\n",
      "48-Giáo trình phân tích hệ thống hướng đối tượng,Phạm, Thị Xuân Lộc,Cần Thơ: Nxb. Đại học Cần Thơ, 2014,004.65 / H516,190026,True\n",
      "4-Analytics, data science, & artificial intelligence,Sharda, Ramesh,Harlow, United Kingdom: Pearson, 2021,658.403 / S531,244700,True\n"
     ]
    }
   ],
   "source": [
    "from home.models import FavList, Book\n",
    "userID = 1\n",
    "books = FavList.objects.filter(user_id=userID).select_related('book')\n",
    "bookList = [fav.book for fav in books]\n",
    "for book in bookList:\n",
    "    print(book)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
